

--- FILE: .gitignore ---

# Ignore venv directories
venv/
.venv/
*/venv/
*/.venv/

.vscode/



--- FILE: clean_dir.py ---

import shutil
from pathlib import Path

def clean_directory(dir_path: Path):
    """Remove all files and subdirectories inside the given directory."""
    if not dir_path.exists():
        return
    if not dir_path.is_dir():
        raise ValueError(f"{dir_path} is not a directory")

    for item in dir_path.iterdir():
        if item.is_file() or item.is_symlink():
            item.unlink()
        elif item.is_dir():
            shutil.rmtree(item)

if __name__ == "__main__":
    target = Path("test_sample")
    clean_directory(target)
    print(f"✅ Cleaned directory: {target}")


--- FILE: convert_format.py ---

from pathlib import Path
from PIL import Image

# === Defaults for standalone ===
INPUT_DIR = Path("test_sample")
OUTPUT_FORMAT = "jpg"
JPEG_QUALITY = 100
WEBP_QUALITY = 100

def process_image(img: Image.Image, filename: str,
                  output_format: str = OUTPUT_FORMAT,
                  jpeg_quality: int = JPEG_QUALITY,
                  webp_quality: int = WEBP_QUALITY):
    """Convert image to given format."""
    ext = output_format.lower()
    out_name = Path(filename).with_suffix(f".{ext}")
    if ext in ["jpg", "jpeg"]:
        return img.convert("RGB"), out_name.name, "JPEG", {"quality": jpeg_quality}
    elif ext == "webp":
        return img.convert("RGB"), out_name.name, "WEBP", {"quality": webp_quality}
    return img.convert("RGB"), out_name.name, ext.upper(), {}

def process_file(img_path: Path,
                 output_format: str = OUTPUT_FORMAT,
                 jpeg_quality: int = JPEG_QUALITY,
                 webp_quality: int = WEBP_QUALITY):
    with Image.open(img_path) as img:
        img, new_name, fmt, params = process_image(img, img_path.name,
                                                   output_format, jpeg_quality, webp_quality)
        out_path = img_path.with_suffix(f".{output_format}")
        out_path.parent.mkdir(parents=True, exist_ok=True)
        img.save(out_path, fmt, **params)
        if out_path != img_path:
            img_path.unlink()
        print(f"✅ Converted {img_path.name} → {out_path.name}")

def main():
    for img_path in INPUT_DIR.glob("*.*"):
        process_file(img_path)

if __name__ == "__main__":
    main()


--- FILE: convex_hull.py ---

import cv2
import mediapipe as mp
import numpy as np
from pathlib import Path
from PIL import Image
from clean_dir import clean_directory

# === Defaults for standalone ===
INPUT_DIR = Path("test_sample")
OUTPUT_DIR = Path("output/convex_hull/results")
DEBUG_DIR = Path("output/convex_hull/debug")
PADDING = 60
SAVE_DEBUG = True
CROP_TO_HULL = False
JPEG_QUALITY, WEBP_QUALITY = 100, 100

# Mediapipe setup
mp_pose = mp.solutions.pose
mp_drawing = mp.solutions.drawing_utils
pose = mp_pose.Pose(static_image_mode=True, model_complexity=2)

def save_image(path: Path, image: np.ndarray,
               jpeg_quality=80, webp_quality=80):
    path.parent.mkdir(parents=True, exist_ok=True)
    img_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    ext = path.suffix.lower()
    if ext in [".jpg", ".jpeg"]:
        img_pil.save(path, "JPEG", quality=jpeg_quality, optimize=True)
    elif ext == ".webp":
        img_pil.save(path, "WEBP", quality=webp_quality, method=6)
    else:
        img_pil.save(path)

def crop_to_mask(image: np.ndarray, mask: np.ndarray):
    ys, xs = np.where(mask > 0)
    if len(xs) == 0 or len(ys) == 0:
        return image
    return image[ys.min():ys.max(), xs.min():xs.max()]

def process_image(img: np.ndarray, filename: str,
                  crop: bool = CROP_TO_HULL,
                  padding: int = PADDING,
                  jpeg_quality: int = JPEG_QUALITY,
                  webp_quality: int = WEBP_QUALITY,
                  save_debug: bool = SAVE_DEBUG,
                  debug_dir: Path = DEBUG_DIR):
    """Apply convex hull mask and optionally crop."""
    h, w, _ = img.shape
    results = pose.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    if not results.pose_landmarks:
        return np.zeros_like(img), filename, None

    points = np.array([[int(lm.x*w), int(lm.y*h)] for lm in results.pose_landmarks.landmark])
    hull = cv2.convexHull(points)

    mask = np.zeros((h, w), dtype=np.uint8)
    cv2.fillConvexPoly(mask, hull, 255)
    kernel = np.ones((padding, padding), np.uint8)
    mask = cv2.dilate(mask, kernel, iterations=1)

    result = np.zeros_like(img)
    result[mask == 255] = img[mask == 255]

    if crop:
        result = crop_to_mask(result, mask)

    debug_img = None
    if save_debug:
        debug_img = img.copy()
        mp_drawing.draw_landmarks(debug_img, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)
        cv2.polylines(debug_img, [hull], True, (255, 0, 0), 2)
        if crop:
            debug_img = crop_to_mask(debug_img, mask)

    return result, filename, debug_img

def process_file(img_path: Path,
                 crop: bool = CROP_TO_HULL,
                 padding: int = PADDING,
                 jpeg_quality: int = JPEG_QUALITY,
                 webp_quality: int = WEBP_QUALITY,
                 save_debug: bool = SAVE_DEBUG,
                 debug_dir: Path = DEBUG_DIR):
    img = cv2.imread(str(img_path))
    if img is None: return
    res, fname, dbg = process_image(img, img_path.name, crop, padding,
                                    jpeg_quality, webp_quality, save_debug, debug_dir)
    out_path = OUTPUT_DIR / fname
    save_image(out_path, res, jpeg_quality, webp_quality)
    if save_debug and dbg is not None:
        save_image(debug_dir / fname, dbg, jpeg_quality, webp_quality)
    print(f"✅ Processed {img_path.name}")

def main():
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    DEBUG_DIR.mkdir(parents=True, exist_ok=True)
    clean_directory(OUTPUT_DIR)
    clean_directory(DEBUG_DIR)
    for f in INPUT_DIR.glob("*.*"):
        process_file(f)

if __name__ == "__main__":
    main()


--- FILE: downquality_and_downscale.py ---

from pathlib import Path
from PIL import Image
from clean_dir import clean_directory

# === Defaults for standalone ===
INPUT_DIR = Path(r"output\grayscale")
OUTPUT_DIR = Path(r"output/downscaled")
SCALE_FACTOR = 1
JPEG_QUALITY, WEBP_QUALITY = 70, 70

def process_image(img: Image.Image, filename: str,
                  scale_factor: float = SCALE_FACTOR,
                  jpeg_quality: int = JPEG_QUALITY,
                  webp_quality: int = WEBP_QUALITY):
    w, h = img.size
    new_size = (int(w*scale_factor), int(h*scale_factor))
    out_img = img.resize(new_size, Image.LANCZOS)
    ext = filename.split(".")[-1].lower()
    if ext in ["jpg","jpeg"]:
        return out_img, filename, "JPEG", {"quality": jpeg_quality}
    elif ext == "webp":
        return out_img, filename, "WEBP", {"quality": webp_quality}
    return out_img, filename, img.format, {}

def process_file(img_path: Path,
                 scale_factor: float = SCALE_FACTOR,
                 jpeg_quality: int = JPEG_QUALITY,
                 webp_quality: int = WEBP_QUALITY):
    with Image.open(img_path) as img:
        out_img, fname, fmt, params = process_image(img, img_path.name,
                                                    scale_factor, jpeg_quality, webp_quality)
        out_path = OUTPUT_DIR / fname
        out_path.parent.mkdir(parents=True, exist_ok=True)
        out_img.save(out_path, fmt, **params)
        print(f"✅ Downscaled {img_path.name}")

def main():
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    clean_directory(OUTPUT_DIR)
    for f in INPUT_DIR.glob("*.*"):
        process_file(f)

if __name__ == "__main__":
    main()


--- FILE: dump_project.py ---

# dump_project.py
# Creates project_dump.txt in the project root, containing all text files
# with a header line showing each file's path relative to the root.

import os
from pathlib import Path

# ---- Tweak these if you like ----
OUTPUT_FILENAME = "project_dump.txt"
MAX_FILE_SIZE_MB = 3  # skip very large files

IGNORE_DIRS = {
    ".git", ".hg", ".svn",
    "__pycache__", ".mypy_cache", ".pytest_cache",
    ".venv", "venv", "env",
    "node_modules", ".cache", ".parcel-cache", ".sass-cache",
    "build", "dist", ".next", ".turbo", "target", ".gradle",
    ".idea", ".vscode", ".terraform"
}

# Common binary/heavy extensions to skip
IGNORE_FILE_EXTS = {
    # compiled/binaries
    ".pyc", ".pyo", ".class", ".o", ".obj", ".a", ".lib",
    ".so", ".dylib", ".dll", ".exe",
    # archives
    ".zip", ".tar", ".gz", ".bz2", ".xz", ".7z", ".rar",
    # media
    ".png", ".jpg", ".jpeg", ".gif", ".bmp", ".ico", ".webp",
    ".mp3", ".wav", ".flac", ".ogg",
    ".mp4", ".mov", ".avi", ".mkv", ".webm",
    # fonts
    ".ttf", ".otf", ".eot", ".woff", ".woff2",
    # dbs and others
    ".db", ".db3", ".sqlite", ".sqlite3", ".pdf", ".bin", ".iso",
    ".log",
    #docs
    ".pdf", ".docx"
}

# Exact file names to skip (secrets/locks/dump itself)
IGNORE_FILE_NAMES = {
    OUTPUT_FILENAME,
    ".env", ".env.local", ".env.development", ".env.production",
    "Pipfile.lock", "poetry.lock", "package-lock.json", "yarn.lock", "pnpm-lock.yaml",
    "Thumbs.db", ".DS_Store"
}


def should_skip_file(path: Path) -> bool:
    name = path.name
    if name in IGNORE_FILE_NAMES:
        return True
    if path.suffix.lower() in IGNORE_FILE_EXTS:
        return True
    try:
        if path.stat().st_size > MAX_FILE_SIZE_MB * 1024 * 1024:
            return True
    except OSError:
        return True  # if we can't stat, skip it
    return False


def main():
    root = Path(__file__).resolve().parent
    out_path = root / OUTPUT_FILENAME

    with out_path.open("w", encoding="utf-8") as out:
        for dirpath, dirnames, filenames in os.walk(root, topdown=True):
            # Prune ignored directories (by name)
            dirnames[:] = [d for d in dirnames if d not in IGNORE_DIRS]

            for fname in filenames:
                fpath = Path(dirpath) / fname
                # Skip dump file and other ignored files
                if should_skip_file(fpath):
                    continue

                rel = fpath.relative_to(root).as_posix()
                out.write(f"\n\n--- FILE: {rel} ---\n\n")

                # Best-effort read in text
                try:
                    with fpath.open("r", encoding="utf-8") as f:
                        out.write(f.read())
                except UnicodeDecodeError:
                    try:
                        with fpath.open("r", encoding="latin-1") as f:
                            out.write(f.read())
                    except Exception as e:
                        out.write(f"[Could not read file: {e}]\n")
                except Exception as e:
                    out.write(f"[Could not read file: {e}]\n")

    print(f"✅ Dump complete → {out_path}")


if __name__ == "__main__":
    main()


--- FILE: grayscale.py ---

from pathlib import Path
from PIL import Image
from clean_dir import clean_directory

# === Defaults for standalone ===
INPUT_DIR = Path(r"output/convex_hull/results")   # fixed path (use raw string or /)
OUTPUT_DIR = Path("output/grayscale")
JPEG_QUALITY, WEBP_QUALITY = 100, 100

def process_image(img: Image.Image, filename: str,
                  jpeg_quality: int = 100,
                  webp_quality: int = 100):
    gray = img.convert("L")
    ext = filename.split(".")[-1].lower()
    if ext in ["jpg", "jpeg"]:
        return gray, filename, "JPEG", {"quality": jpeg_quality}
    elif ext == "webp":
        return gray, filename, "WEBP", {"quality": webp_quality}
    return gray, filename, img.format, {}

def process_file(img_path: Path,
                 jpeg_quality: int = JPEG_QUALITY,
                 webp_quality: int = WEBP_QUALITY):
    with Image.open(img_path) as img:
        gray, fname, fmt, params = process_image(img, img_path.name,
                                                 jpeg_quality, webp_quality)
        out_path = OUTPUT_DIR / fname
        out_path.parent.mkdir(parents=True, exist_ok=True)
        gray.save(out_path, fmt, **params)
        print(f"✅ Grayscaled {img_path.name}")

def main():
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    clean_directory(OUTPUT_DIR)
    for f in INPUT_DIR.glob("*.*"):
        process_file(f)

if __name__ == "__main__":
    main()


--- FILE: requirements.txt ---

matplotlib
numpy
mediapipe
opencv-python
pandas
pytest

--- FILE: run.py ---

from pathlib import Path
from PIL import Image
import cv2, numpy as np, shutil, json

# Import helpers
from sample_creator import create_test_sample
from convert_format import process_image as convert_img
from convex_hull import process_image as convex_img
from downquality_and_downscale import process_image as downscale_img
from grayscale import process_image as gray_img

# ===================================================
# CONFIG (two options)
# ===================================================

# Option 1: Paste JSON as a string here
CONFIG_JSON = """
{
    "name": "WebP Grayscale",
    "SAMPLE_INPUT_DIR": "C:/PoiseVideos/4825_Prasanna K.B_189_20250916173306/4825_Prasanna K.B_189_20250916173306",
    "SAMPLE_SIZE": 50,
    "TOGGLE_SAMPLE_CREATOR": true,
    "TOGGLE_CONVERT_FORMAT": true,
    "TOGGLE_CONVEX_HULL": true,
    "TOGGLE_CONVEX_HULL_CROP": false,
    "TOGGLE_GRAYSCALE": true,
    "TOGGLE_DOWNSCALE": false,
    "OUTPUT_FORMAT": "webp",
    "JPEG_QUALITY": 100,
    "WEBP_QUALITY": 100,
    "SCALE_FACTOR": 1,
    "PADDING": 60,
    "SAVE_DEBUG": false
  }
"""

# Option 2: Load from external JSON file (uncomment this)
# CONFIG_PATH = Path("config.json")
# with open(CONFIG_PATH, "r", encoding="utf-8") as f:
#     CONFIG = json.load(f)

# Use Option 1 by default
CONFIG = json.loads(CONFIG_JSON)

# --- Convert certain keys into Path objects ---
if "SAMPLE_INPUT_DIR" in CONFIG:
    CONFIG["SAMPLE_INPUT_DIR"] = Path(CONFIG["SAMPLE_INPUT_DIR"])
if "SAMPLE_OUTPUT_DIR" not in CONFIG:
    CONFIG["SAMPLE_OUTPUT_DIR"] = Path("test_sample")

# Output dirs
OUTPUT_DIR = Path("output")
FINAL_RESULT_DIR = OUTPUT_DIR / "final_results"


def pipeline(cfg: dict):
    FINAL_RESULT_DIR.mkdir(parents=True, exist_ok=True)

    # Stage 1: Sample creation
    if cfg["TOGGLE_SAMPLE_CREATOR"]:
        create_test_sample(cfg["SAMPLE_INPUT_DIR"], cfg["SAMPLE_OUTPUT_DIR"], cfg["SAMPLE_SIZE"])
        source = cfg["SAMPLE_OUTPUT_DIR"]
    else:
        source = cfg["SAMPLE_INPUT_DIR"]

    files = list(source.glob("*.*"))
    if not files:
        print(f"⚠️ No files found in {source}")
        return

    print(f"📂 Found {len(files)} files to process from {source}")

    for f in files:
        try:
            img = Image.open(f)
            fname, fmt, params = f.name, img.format, {}

            # Stage 2: Convert format
            if cfg["TOGGLE_CONVERT_FORMAT"]:
                img, fname, fmt, params = convert_img(
                    img, fname,
                    cfg["OUTPUT_FORMAT"],
                    cfg["JPEG_QUALITY"],
                    cfg["WEBP_QUALITY"]
                )

            # Stage 3: Convex hull
            if cfg["TOGGLE_CONVEX_HULL"]:
                cv_img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
                cv_res, fname, dbg = convex_img(
                    cv_img, fname,
                    crop=cfg["TOGGLE_CONVEX_HULL_CROP"],
                    padding=cfg["PADDING"],
                    jpeg_quality=cfg["JPEG_QUALITY"],
                    webp_quality=cfg["WEBP_QUALITY"],
                    save_debug=cfg["SAVE_DEBUG"],
                    debug_dir=OUTPUT_DIR / "convex_hull/debug"
                )
                img = Image.fromarray(cv2.cvtColor(cv_res, cv2.COLOR_BGR2RGB))

            # Stage 4: Downscale
            if cfg["TOGGLE_DOWNSCALE"]:
                img, fname, fmt, params = downscale_img(
                    img, fname,
                    scale_factor=cfg["SCALE_FACTOR"],
                    jpeg_quality=cfg["JPEG_QUALITY"],
                    webp_quality=cfg["WEBP_QUALITY"]
                )

            # Stage 5: Grayscale
            if cfg["TOGGLE_GRAYSCALE"]:
                img, fname, fmt, params = gray_img(
                    img, fname,
                    jpeg_quality=cfg["JPEG_QUALITY"],
                    webp_quality=cfg["WEBP_QUALITY"]
                )

            # Final save
            out_path = FINAL_RESULT_DIR / fname
            img.save(out_path, fmt, **params)
            print(f"✅ Final saved {fname}")

        except Exception as e:
            print(f"⚠️ Failed {f.name}: {e}")


if __name__ == "__main__":
    if FINAL_RESULT_DIR.exists():
        shutil.rmtree(FINAL_RESULT_DIR)
    FINAL_RESULT_DIR.mkdir(parents=True, exist_ok=True)

    print(f"🚀 Running pipeline: {CONFIG['name']}")
    pipeline(CONFIG)
    print("🎉 Pipeline finished!")


--- FILE: sample_creator.py ---

import random
import shutil
from pathlib import Path
from clean_dir import clean_directory

# === Defaults for standalone ===
INPUT_DIR = Path(r"C:\PoiseVideos\4825_Prasanna K.B_189_20250916173306\4825_Prasanna K.B_189_20250916173306")        # main dataset
OUTPUT_DIR = Path("test_sample")
SAMPLE_SIZE = 100

def create_test_sample(input_dir: Path, output_dir: Path, sample_size: int):
    """Copy a random sample of images from input_dir to output_dir."""
    images = sorted([p for p in input_dir.iterdir() if p.suffix.lower() in {".jpg", ".png", ".webp"}])
    if not images:
        raise ValueError(f"No images found in {input_dir}")
    if sample_size > len(images):
        raise ValueError("Sample size larger than available images")

    output_dir.mkdir(parents=True, exist_ok=True)
    clean_directory(output_dir)

    sampled = random.sample(images, sample_size)
    for img in sampled:
        shutil.copy(img, output_dir / img.name)

    print(f"✅ Copied {sample_size} images to {output_dir}")

if __name__ == "__main__":
    create_test_sample(INPUT_DIR, OUTPUT_DIR, SAMPLE_SIZE)


--- FILE: test_pipeline_report.py ---

import shutil
from pathlib import Path
import run
import matplotlib.pyplot as plt
import pandas as pd
from datetime import datetime
import json
import textwrap
from PIL import Image

#Enter the name of your test 
TEST_NAME = "Individual_controls_testing"

#Enter the relative path of your test case json
TEST_JSON_PATH = r"test_cases\combination_of_controls.json"

'''--------------------------------------------------------------------------------------------------------------------------------'''

def get_folder_size(path: Path) -> int:
    return sum(f.stat().st_size for f in path.glob("**/*") if f.is_file())

# ==============================
# Load test cases from JSON
# ==============================
def load_test_cases(json_file=Path(TEST_JSON_PATH)):
    with open(json_file, "r", encoding="utf-8") as f:
        raw_cases = json.load(f)

    # Convert SAMPLE_INPUT_DIR strings into Path objects
    for case in raw_cases:
        case["SAMPLE_INPUT_DIR"] = Path(case["SAMPLE_INPUT_DIR"])
        case["SAMPLE_OUTPUT_DIR"] = Path("test_sample")  # always reset to same folder
    return raw_cases


def run_experiments(test_cases, run_dir: Path):
    results = []
    buffer_dir = run_dir / "buffers"
    buffer_dir.mkdir(parents=True, exist_ok=True)

    for idx, case in enumerate(test_cases):
        print(f"\n=== Running test case: {case['name']} ===")

        # Reset final results dir before each case
        if run.FINAL_RESULT_DIR.exists():
            shutil.rmtree(run.FINAL_RESULT_DIR)
        run.FINAL_RESULT_DIR.mkdir(parents=True, exist_ok=True)

        # Merge with defaults
        merged_cfg = {**run.CONFIG, **case}

        # Run pipeline with this test case config
        run.pipeline(merged_cfg)

        # Measure sizes
        sample_size = get_folder_size(merged_cfg["SAMPLE_OUTPUT_DIR"])
        final_size = get_folder_size(run.FINAL_RESULT_DIR)
        compression = 100 * (1 - final_size / sample_size) if sample_size > 0 else 0

        # ---- Pick one sample + corresponding result to buffer ----
        sample_images = list(merged_cfg["SAMPLE_OUTPUT_DIR"].glob("*.*"))
        final_images = list(run.FINAL_RESULT_DIR.glob("*.*"))

        if sample_images and final_images:
            sample_img = sample_images[0]
            final_img = final_images[0]

            case_buf_dir = buffer_dir / f"case_{idx+1}"
            case_buf_dir.mkdir(parents=True, exist_ok=True)

            # Copy
            sample_copy = case_buf_dir / f"sample{sample_img.suffix}"
            final_copy = case_buf_dir / f"final{final_img.suffix}"
            shutil.copy(sample_img, sample_copy)
            shutil.copy(final_img, final_copy)

        # Record result
        results.append({
            "Case": merged_cfg["name"],
            "Format": merged_cfg["OUTPUT_FORMAT"],
            "JPEG_Q": merged_cfg["JPEG_QUALITY"],
            "WEBP_Q": merged_cfg["WEBP_QUALITY"],
            "Scale": merged_cfg["SCALE_FACTOR"],
            "ConvexHull": merged_cfg["TOGGLE_CONVEX_HULL"],
            "Crop": merged_cfg["TOGGLE_CONVEX_HULL_CROP"],
            "Grayscale": merged_cfg["TOGGLE_GRAYSCALE"],
            "Downscale": merged_cfg["TOGGLE_DOWNSCALE"],
            "SampleSizeKB": sample_size / 1024,
            "FinalSizeKB": final_size / 1024,
            "Compression%": compression,
        })

    return pd.DataFrame(results)


def generate_report(df: pd.DataFrame, run_dir: Path):
    # Wrap long text in Case column for better fit
    df = df.copy()
    df["Case"] = df["Case"].apply(lambda x: "\n".join(textwrap.wrap(x, width=18)))

    # Save CSV
    df.to_csv(run_dir / "compression_report.csv", index=False)

    # Bar chart
    plt.figure(figsize=(10,6))
    bar_width = 0.35
    x = range(len(df))
    plt.bar([i - bar_width/2 for i in x], df["SampleSizeKB"], width=bar_width, label="Test Sample (total)")
    plt.bar([i + bar_width/2 for i in x], df["FinalSizeKB"], width=bar_width, label="Final Result (total)")
    plt.xticks(x, df["Case"], rotation=20, ha="right")
    plt.ylabel("Size (KB)")
    plt.title("Total Folder Size: Test Sample vs Final Result")
    plt.legend()
    plt.tight_layout()
    plt.savefig(run_dir / "sizes_comparison.png")

    # Line chart
    plt.figure(figsize=(10,6))
    plt.plot(df["Case"], df["Compression%"], marker="o")
    plt.ylabel("Compression (%)")
    plt.title("Compression Achieved per Test Case")
    plt.xticks(rotation=20, ha="right")
    plt.tight_layout()
    plt.savefig(run_dir / "compression_percent.png")

    # Combine into PDF
    from matplotlib.backends.backend_pdf import PdfPages
    with PdfPages(run_dir / "compression_report.pdf") as pdf:
        # --- Fix table layout ---
        # Drop only per-image sizes (if present)
        df_table = df.drop(columns=["SampleImageSizeKB", "FinalImageSizeKB"], errors="ignore")

        fig, ax = plt.subplots(figsize=(12,4))
        ax.axis("tight"); ax.axis("off")
        table = ax.table(cellText=df_table.round(2).values,
                         colLabels=df_table.columns,
                         loc="center")
        table.auto_set_font_size(False)
        table.set_fontsize(8)
        table.scale(1.2, 1.4)
        table.auto_set_column_width(col=list(range(len(df_table.columns))))

        # --- Dynamic row heights ---
        for (row, col), cell in table.get_celld().items():
            if row == 0:  # header
                cell.set_height(0.12)
                cell.set_text_props(weight="bold", ha="center", va="center")
            else:
                txt = str(df_table.iloc[row-1, col])
                num_lines = txt.count("\n") + 1
                cell.set_height(0.08 * num_lines)
                cell.set_text_props(ha="center", va="center")

        pdf.savefig(fig)

        # Add graphs
        pdf.savefig(plt.figure(1))
        pdf.savefig(plt.figure(2))

        # ---- Add case-by-case image slides ----
        buffer_dir = run_dir / "buffers"
        for idx, case in enumerate(df["Case"], start=1):
            case_buf_dir = buffer_dir / f"case_{idx}"
            sample_candidates = list(case_buf_dir.glob("sample.*"))
            final_candidates = list(case_buf_dir.glob("final.*"))
            if not sample_candidates or not final_candidates:
                continue

            sample_img = sample_candidates[0]
            final_img = final_candidates[0]

            # Get resolution
            s_res = Image.open(sample_img).size
            f_res = Image.open(final_img).size

            # Get sizes
            s_size = sample_img.stat().st_size / 1024
            f_size = final_img.stat().st_size / 1024

            # Get quality info
            row = df.iloc[idx-1]
            q_info = f"JPEG_Q={row['JPEG_Q']} | WEBP_Q={row['WEBP_Q']} | Format={row['Format']}"

            # Plot side-by-side with resolution + size
            fig, axs = plt.subplots(1, 2, figsize=(12,6))
            for ax, img_path, title, res, size_kb in [
                (axs[0], sample_img, "Sample", s_res, s_size),
                (axs[1], final_img, "Final", f_res, f_size),
            ]:
                img = plt.imread(img_path)
                ax.imshow(img)
                ax.set_title(f"{title}\n{res[0]}x{res[1]} | {size_kb:.1f} KB")
                if title == "Final":
                    ax.set_xlabel(q_info)
                ax.set_xticks(range(0, res[0], max(1,res[0]//5)))
                ax.set_yticks(range(0, res[1], max(1,res[1]//5)))

            plt.suptitle(f"Case {idx}: {row['Case']}")
            pdf.savefig(fig)
            plt.close(fig)

    print(f"✅ Report generated in: {run_dir}")


if __name__ == "__main__":
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    run_dir = Path("test_cases") / TEST_NAME / timestamp
    run_dir.mkdir(parents=True, exist_ok=True)

    cases = load_test_cases(TEST_JSON_PATH)
    df = run_experiments(cases, run_dir)
    generate_report(df, run_dir)


--- FILE: test_cases/combination_of_controls.json ---

[
  {
    "name": "WebP default",
    "SAMPLE_INPUT_DIR": "C:/PoiseVideos/4825_Prasanna K.B_189_20250916173306/4825_Prasanna K.B_189_20250916173306",
    "SAMPLE_SIZE": 50,
    "TOGGLE_SAMPLE_CREATOR": true,
    "TOGGLE_CONVERT_FORMAT": true,
    "TOGGLE_CONVEX_HULL": true,
    "TOGGLE_CONVEX_HULL_CROP": false,
    "TOGGLE_GRAYSCALE": false,
    "TOGGLE_DOWNSCALE": false,
    "OUTPUT_FORMAT": "webp",
    "JPEG_QUALITY": 100,
    "WEBP_QUALITY": 100,
    "SCALE_FACTOR": 1,
    "PADDING": 60,
    "SAVE_DEBUG": false
  },
  {
    "name": "WebP Grayscale + QF",
    "SAMPLE_INPUT_DIR": "C:/PoiseVideos/4825_Prasanna K.B_189_20250916173306/4825_Prasanna K.B_189_20250916173306",
    "SAMPLE_SIZE": 50,
    "TOGGLE_SAMPLE_CREATOR": true,
    "TOGGLE_CONVERT_FORMAT": true,
    "TOGGLE_CONVEX_HULL": true,
    "TOGGLE_CONVEX_HULL_CROP": false,
    "TOGGLE_GRAYSCALE": true,
    "TOGGLE_DOWNSCALE": false,
    "OUTPUT_FORMAT": "webp",
    "JPEG_QUALITY": 75,
    "WEBP_QUALITY": 75,
    "SCALE_FACTOR": 1,
    "PADDING": 60,
    "SAVE_DEBUG": false
  },
  {
    "name": "WebP Grayscale + QF + Crop",
    "SAMPLE_INPUT_DIR": "C:/PoiseVideos/4825_Prasanna K.B_189_20250916173306/4825_Prasanna K.B_189_20250916173306",
    "SAMPLE_SIZE": 50,
    "TOGGLE_SAMPLE_CREATOR": true,
    "TOGGLE_CONVERT_FORMAT": true,
    "TOGGLE_CONVEX_HULL": true,
    "TOGGLE_CONVEX_HULL_CROP": true,
    "TOGGLE_GRAYSCALE": true,
    "TOGGLE_DOWNSCALE": false,
    "OUTPUT_FORMAT": "webp",
    "JPEG_QUALITY": 75,
    "WEBP_QUALITY": 75,
    "SCALE_FACTOR": 1,
    "PADDING": 60,
    "SAVE_DEBUG": false
  },
  {
    "name": "WebP Grayscale + QF + Downscale",
    "SAMPLE_INPUT_DIR": "C:/PoiseVideos/4825_Prasanna K.B_189_20250916173306/4825_Prasanna K.B_189_20250916173306",
    "SAMPLE_SIZE": 50,
    "TOGGLE_SAMPLE_CREATOR": true,
    "TOGGLE_CONVERT_FORMAT": true,
    "TOGGLE_CONVEX_HULL": true,
    "TOGGLE_CONVEX_HULL_CROP": false,
    "TOGGLE_GRAYSCALE": true,
    "TOGGLE_DOWNSCALE": false,
    "OUTPUT_FORMAT": "webp",
    "JPEG_QUALITY": 75,
    "WEBP_QUALITY": 75,
    "SCALE_FACTOR": 0.75,
    "PADDING": 60,
    "SAVE_DEBUG": false
  },
  {
    "name": "WebP Grayscale + QF + Downscale + Crop",
    "SAMPLE_INPUT_DIR": "C:/PoiseVideos/4825_Prasanna K.B_189_20250916173306/4825_Prasanna K.B_189_20250916173306",
    "SAMPLE_SIZE": 50,
    "TOGGLE_SAMPLE_CREATOR": true,
    "TOGGLE_CONVERT_FORMAT": true,
    "TOGGLE_CONVEX_HULL": true,
    "TOGGLE_CONVEX_HULL_CROP": true,
    "TOGGLE_GRAYSCALE": true,
    "TOGGLE_DOWNSCALE": false,
    "OUTPUT_FORMAT": "webp",
    "JPEG_QUALITY": 75,
    "WEBP_QUALITY": 75,
    "SCALE_FACTOR": 0.75,
    "PADDING": 60,
    "SAVE_DEBUG": false
  }
  
]


--- FILE: test_cases/Individual_controls_testing.json ---

[
  {
    "name": "WebP default",
    "SAMPLE_INPUT_DIR": "C:/PoiseVideos/4825_Prasanna K.B_189_20250916173306/4825_Prasanna K.B_189_20250916173306",
    "SAMPLE_SIZE": 50,
    "TOGGLE_SAMPLE_CREATOR": true,
    "TOGGLE_CONVERT_FORMAT": true,
    "TOGGLE_CONVEX_HULL": true,
    "TOGGLE_CONVEX_HULL_CROP": false,
    "TOGGLE_GRAYSCALE": false,
    "TOGGLE_DOWNSCALE": false,
    "OUTPUT_FORMAT": "webp",
    "JPEG_QUALITY": 100,
    "WEBP_QUALITY": 100,
    "SCALE_FACTOR": 1,
    "PADDING": 60,
    "SAVE_DEBUG": false
  },
  {
    "name": "WebP Crop",
    "SAMPLE_INPUT_DIR": "C:/PoiseVideos/4825_Prasanna K.B_189_20250916173306/4825_Prasanna K.B_189_20250916173306",
    "SAMPLE_SIZE": 50,
    "TOGGLE_SAMPLE_CREATOR": true,
    "TOGGLE_CONVERT_FORMAT": true,
    "TOGGLE_CONVEX_HULL": true,
    "TOGGLE_CONVEX_HULL_CROP": true,
    "TOGGLE_GRAYSCALE": false,
    "TOGGLE_DOWNSCALE": true,
    "OUTPUT_FORMAT": "webp",
    "JPEG_QUALITY": 100,
    "WEBP_QUALITY": 100,
    "SCALE_FACTOR": 1,
    "PADDING": 60,
    "SAVE_DEBUG": false
  },
  {
    "name": "WebP Grayscale",
    "SAMPLE_INPUT_DIR": "C:/PoiseVideos/4825_Prasanna K.B_189_20250916173306/4825_Prasanna K.B_189_20250916173306",
    "SAMPLE_SIZE": 50,
    "TOGGLE_SAMPLE_CREATOR": true,
    "TOGGLE_CONVERT_FORMAT": true,
    "TOGGLE_CONVEX_HULL": true,
    "TOGGLE_CONVEX_HULL_CROP": false,
    "TOGGLE_GRAYSCALE": true,
    "TOGGLE_DOWNSCALE": false,
    "OUTPUT_FORMAT": "webp",
    "JPEG_QUALITY": 100,
    "WEBP_QUALITY": 100,
    "SCALE_FACTOR": 1,
    "PADDING": 60,
    "SAVE_DEBUG": false
  },
  {
    "name": "WebP Quality factor",
    "SAMPLE_INPUT_DIR": "C:/PoiseVideos/4825_Prasanna K.B_189_20250916173306/4825_Prasanna K.B_189_20250916173306",
    "SAMPLE_SIZE": 50,
    "TOGGLE_SAMPLE_CREATOR": true,
    "TOGGLE_CONVERT_FORMAT": true,
    "TOGGLE_CONVEX_HULL": true,
    "TOGGLE_CONVEX_HULL_CROP": false,
    "TOGGLE_GRAYSCALE": false,
    "TOGGLE_DOWNSCALE": true,
    "OUTPUT_FORMAT": "webp",
    "JPEG_QUALITY": 75,
    "WEBP_QUALITY": 75,
    "SCALE_FACTOR": 1,
    "PADDING": 60,
    "SAVE_DEBUG": false
  },
  {
    "name": "WebP Downscaling",
    "SAMPLE_INPUT_DIR": "C:/PoiseVideos/4825_Prasanna K.B_189_20250916173306/4825_Prasanna K.B_189_20250916173306",
    "SAMPLE_SIZE": 50,
    "TOGGLE_SAMPLE_CREATOR": true,
    "TOGGLE_CONVERT_FORMAT": true,
    "TOGGLE_CONVEX_HULL": true,
    "TOGGLE_CONVEX_HULL_CROP": false,
    "TOGGLE_GRAYSCALE": false,
    "TOGGLE_DOWNSCALE": true,
    "OUTPUT_FORMAT": "webp",
    "JPEG_QUALITY": 100,
    "WEBP_QUALITY": 100,
    "SCALE_FACTOR": 0.8,
    "PADDING": 60,
    "SAVE_DEBUG": false
  }
]


--- FILE: test_cases/Individual_controls_testing/20251001_131810/compression_report.csv ---

Case,Format,JPEG_Q,WEBP_Q,Scale,ConvexHull,Crop,Grayscale,Downscale,SampleSizeKB,FinalSizeKB,Compression%
WebP default,webp,100,100,1.0,True,False,False,False,344.3447265625,473.703125,-37.56653970828878
WebP Crop,webp,100,100,1.0,True,True,False,True,343.9619140625,671.76953125,-95.30346348983723
WebP Grayscale,webp,100,100,1.0,True,False,True,False,344.51953125,417.333984375,-21.135072621517747
"WebP Quality
factor",webp,75,75,1.0,True,False,False,True,344.63671875,215.76171875,37.394448411484014
WebP Downscaling,webp,100,100,0.8,True,False,False,True,344.0087890625,594.185546875,-72.72394362198912


--- FILE: test_cases/Individual_controls_testing/20251001_133520/compression_report.csv ---

Case,Format,JPEG_Q,WEBP_Q,Scale,ConvexHull,Crop,Grayscale,Downscale,SampleSizeKB,FinalSizeKB,Compression%
WebP default,webp,100,100,1.0,True,False,False,False,343.6015625,455.10546875,-32.45151315340715
"WebP Grayscale +
QF",webp,75,75,1.0,True,False,True,False,343.177734375,190.4140625,44.514447347003816
"WebP Grayscale +
QF + Crop",webp,75,75,1.0,True,True,True,False,343.8740234375,221.986328125,35.445450079090776
"WebP Grayscale +
QF + Downscale",webp,75,75,0.75,True,False,True,False,344.142578125,198.236328125,42.397035204113486
"WebP Grayscale +
QF + Downscale +
Crop",webp,75,75,0.75,True,True,True,False,343.43359375,223.21484375,35.00494773598426


--- FILE: test_cases/Individual_controls_testing/20251001_134123/compression_report.csv ---

Case,Format,JPEG_Q,WEBP_Q,Scale,ConvexHull,Crop,Grayscale,Downscale,SampleSizeKB,FinalSizeKB,Compression%
WebP default,webp,100,100,1.0,True,False,False,False,343.46484375,463.580078125,-34.97162418824706
"WebP Grayscale +
QF",webp,75,75,1.0,True,False,True,False,344.7607421875,205.677734375,40.34189244692452
"WebP Grayscale +
QF + Crop",webp,75,75,1.0,True,True,True,False,342.830078125,219.0078125,36.117678560237906
"WebP Grayscale +
QF + Downscale",webp,75,75,0.75,True,False,True,False,344.3740234375,203.26953125,40.9741974086814
"WebP Grayscale +
QF + Downscale +
Crop",webp,75,75,0.75,True,True,True,False,343.4658203125,221.779296875,35.42900522875445
